[
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "ActivityData",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class ActivityData(BaseModel):\n    steps: int\n    weight: float\n    hour: int\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):\n    # ---------------------------------------------------------\n    # ðŸ§  PART 1: PREDICT CALORIES\n    # ---------------------------------------------------------",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,\n            calories REAL",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_history():\n    conn = sqlite3.connect(DB_FILE)\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    cursor.execute('SELECT * FROM logs ORDER BY id DESC LIMIT 20')\n    rows = cursor.fetchall()\n    conn.close()\n    clean_history = []\n    for row in rows:\n        clean_history.append({",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def home():\n    return {\"status\": \"Online\", \"framework\": \"FastAPI + SQLite\"}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = FastAPI()\n# --- DATABASE SETUP ---\nDB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DB_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "n_samples = 10000\n# 1. Generate Data\nsteps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "steps",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "steps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "weight",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "weight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "hours",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "hours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "base_burn",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "base_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "noise",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "noise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)\n# Check File Size\nsize_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "size_mb",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "size_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    }
]