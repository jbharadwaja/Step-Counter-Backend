[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "analytics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "analytics",
        "description": "analytics",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "predict_end_of_day_steps",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def predict_end_of_day_steps(current_steps, current_time, historical_data):\n    \"\"\"\n    Smarter Model v4 (Robust Fallback).\n    \"\"\"\n    # 1. SAFETY: If no history, assume Day 1 behavior\n    if not historical_data or len(historical_data) < 1:\n        return fallback_prediction(current_steps, current_time, [])\n    # 2. PREPARE DATA\n    try:\n        df = pd.DataFrame(historical_data)",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "fallback_prediction",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def fallback_prediction(current_steps, current_time, daily_totals_df):\n    \"\"\"\n    üü¢ SMART FALLBACK: \n    If the AI fails (or goal is met), we trust 'Current Steps' more as the day progresses.\n    \"\"\"\n    hour = current_time.hour\n    if hour == 0: hour = 1\n    # 1. Calculate Confidence based on Time\n    # At 8 AM (2/16 hours): Confidence 40%\n    # At 8 PM (14/16 hours): Confidence 95% (Because the day is done!)",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "calculate_consistency_from_df",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def calculate_consistency_from_df(valid_days_df):\n    \"\"\"\n    Calculates consistency score. \n    Ignores 'Today' if it drags the average down, and handles new users gently.\n    \"\"\"\n    # 1. NEW USER CHECK\n    # If we have less than 3 days of history, calculating Standard Deviation is unfair.\n    # We return a high default score to be encouraging.\n    if valid_days_df.empty or len(valid_days_df) < 3:\n        return 90 # \"Great Start / Very Stable\"",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "analyze_weekly_pattern_from_df",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def analyze_weekly_pattern_from_df(valid_days_df):\n    if valid_days_df.empty: return [0]*7\n    valid_days_df['weekday'] = valid_days_df['date'].dt.dayofweek\n    weekday_avgs = valid_days_df.groupby('weekday')['actual_final_total'].mean()\n    weekday_avgs = weekday_avgs.reindex(range(7), fill_value=0)\n    return weekday_avgs.astype(int).tolist()\ndef determine_walker_type(df):\n    if df.empty: return \"Newbie ü•ö\"\n    try:\n        morning = df[(df['hour'] >= 5) & (df['hour'] < 12)]['steps'].sum()",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "determine_walker_type",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def determine_walker_type(df):\n    if df.empty: return \"Newbie ü•ö\"\n    try:\n        morning = df[(df['hour'] >= 5) & (df['hour'] < 12)]['steps'].sum()\n        noon = df[(df['hour'] >= 12) & (df['hour'] < 17)]['steps'].sum()\n        evening = df[(df['hour'] >= 17) & (df['hour'] < 23)]['steps'].sum()\n        total = morning + noon + evening\n        if total == 0: return \"Newbie ü•ö\"\n        if morning > noon and morning > evening: return \"Morning Lark üåÖ\"\n        elif noon > morning and noon > evening: return \"Lunchtime Stroller ‚òÄÔ∏è\"",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "calculate_consistency",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def calculate_consistency(data): return 0\ndef analyze_weekly_pattern(data): return [0]*7\ndef generate_trend_message(p, a): return \"\"",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "analyze_weekly_pattern",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def analyze_weekly_pattern(data): return [0]*7\ndef generate_trend_message(p, a): return \"\"",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "generate_trend_message",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def generate_trend_message(p, a): return \"\"",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "ActivityData",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class ActivityData(BaseModel):\n    steps: int\n    weight: float\n    hour: int\n# 2. For Step Prediction (New Feature)\nclass HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "HistoryPoint",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "PredictionRequest",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):\n    # ---------------------------------------------------------\n    # üß† PART 1: PREDICT CALORIES\n    # ---------------------------------------------------------\n    if model:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,\n            calories REAL",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_history():\n    conn = sqlite3.connect(DB_FILE)\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    cursor.execute('SELECT * FROM logs ORDER BY id DESC LIMIT 20')\n    rows = cursor.fetchall()\n    conn.close()\n    clean_history = []\n    for row in rows:\n        clean_history.append({",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def home():\n    return {\"status\": \"Online\", \"framework\": \"FastAPI + SQLite\"}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = FastAPI()\n# --- DATABASE SETUP ---\nDB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DB_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "n_samples = 10000\n# 1. Generate Data\nsteps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "steps",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "steps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "weight",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "weight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "hours",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "hours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"üß† Training Optimized Model...\")\n# üü¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "base_burn",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "base_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"üß† Training Optimized Model...\")\n# üü¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"üß† Training Optimized Model...\")\n# üü¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"üíæ Saving with compression...\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "noise",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "noise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"üß† Training Optimized Model...\")\n# üü¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"üíæ Saving with compression...\")\n# üü¢ CHANGE 2: compress=3 drastically reduces file size",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"üß† Training Optimized Model...\")\n# üü¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"üíæ Saving with compression...\")\n# üü¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"üíæ Saving with compression...\")\n# üü¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)\n# Check File Size\nsize_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"‚úÖ Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "size_mb",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "size_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"‚úÖ Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    }
]