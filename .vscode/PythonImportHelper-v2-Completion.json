[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "analytics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "analytics",
        "description": "analytics",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "predict_end_of_day_steps",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def predict_end_of_day_steps(current_steps, current_time, historical_data):\n    \"\"\"\n    Production-Ready Step Prediction Engine (v2 - Dampened).\n    Uses Linear Regression but blends it with historical averages to prevent wild outliers.\n    \"\"\"\n    # 1. SAFETY CHECKS\n    # If not enough data, use simple fallback\n    if not historical_data or len(historical_data) < 5:\n        return fallback_prediction(current_steps, current_time)\n    # 2. PREPARE DATA",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "fallback_prediction",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def fallback_prediction(current_steps, current_time):\n    \"\"\"Simple multiplier fallback if AI fails or data is missing.\"\"\"\n    hour = current_time.hour\n    if hour == 0: hour = 1\n    # Conservative Estimate: Assume steady walking over 16 active hours\n    fraction_of_day_passed = min((hour - 6) / 16.0, 1.0) \n    if fraction_of_day_passed <= 0: fraction_of_day_passed = 0.05\n    projected = current_steps / fraction_of_day_passed\n    return {\n        \"projected_steps\": int(projected),",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "ActivityData",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class ActivityData(BaseModel):\n    steps: int\n    weight: float\n    hour: int\n# 2. For Step Prediction (New Feature)\nclass HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "HistoryPoint",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "PredictionRequest",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):\n    # ---------------------------------------------------------\n    # ðŸ§  PART 1: PREDICT CALORIES\n    # ---------------------------------------------------------\n    if model:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,\n            calories REAL",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_history():\n    conn = sqlite3.connect(DB_FILE)\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    cursor.execute('SELECT * FROM logs ORDER BY id DESC LIMIT 20')\n    rows = cursor.fetchall()\n    conn.close()\n    clean_history = []\n    for row in rows:\n        clean_history.append({",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def home():\n    return {\"status\": \"Online\", \"framework\": \"FastAPI + SQLite\"}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = FastAPI()\n# --- DATABASE SETUP ---\nDB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DB_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "n_samples = 10000\n# 1. Generate Data\nsteps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "steps",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "steps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "weight",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "weight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "hours",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "hours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "base_burn",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "base_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "noise",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "noise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)\n# Check File Size\nsize_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "size_mb",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "size_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    }
]