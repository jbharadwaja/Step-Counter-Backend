[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "analytics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "analytics",
        "description": "analytics",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "predict_end_of_day_steps",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def predict_end_of_day_steps(current_steps, current_time, historical_data):\n    \"\"\"\n    Smarter Model v3 (Time-Weighted & Cleaned).\n    - Removes 'lazy/sick' days (outliers) from training.\n    - Trusts 'Average' in the morning.\n    - Trusts 'AI Projection' in the evening.\n    \"\"\"\n    # 1. SAFETY & DATA VALIDATION\n    if not historical_data or len(historical_data) < 5:\n        return fallback_prediction(current_steps, current_time)",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "fallback_prediction",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def fallback_prediction(current_steps, current_time):\n    \"\"\"Conservative fallback using remaining hours.\"\"\"\n    hour = current_time.hour\n    if hour == 0: hour = 1\n    fraction_passed = min((hour - 6) / 16.0, 1.0)\n    if fraction_passed <= 0.1: \n        projected = max(current_steps * 2, 4000) \n    else:\n        projected = current_steps / fraction_passed\n    return {",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "calculate_consistency",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def calculate_consistency(past_steps_list: list) -> int:\n    \"\"\"Wrapper for main.py to call consistency logic with a simple list.\"\"\"\n    if not past_steps_list: return 0\n    df = pd.DataFrame({'actual_final_total': past_steps_list})\n    return calculate_consistency_from_df(df)\ndef calculate_consistency_from_df(valid_days_df):\n    \"\"\"Internal logic using Pandas\"\"\"\n    if valid_days_df.empty: return 0\n    std_dev = valid_days_df['actual_final_total'].std()\n    mean_val = valid_days_df['actual_final_total'].mean()",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "calculate_consistency_from_df",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def calculate_consistency_from_df(valid_days_df):\n    \"\"\"Internal logic using Pandas\"\"\"\n    if valid_days_df.empty: return 0\n    std_dev = valid_days_df['actual_final_total'].std()\n    mean_val = valid_days_df['actual_final_total'].mean()\n    if mean_val > 0:\n        cv = std_dev / mean_val\n        # CV of 0 = 100 Score. CV of 1.0 = 0 Score.\n        score = max(0, 100 - (cv * 100))\n        return int(score)",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "analyze_weekly_pattern",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def analyze_weekly_pattern(history: list) -> list:\n    \"\"\"Wrapper for main.py to call weekly pattern logic.\"\"\"\n    if not history: return [0]*7\n    try:\n        df = pd.DataFrame(history)\n        df['date'] = pd.to_datetime(df['date'])\n        daily_totals = df.groupby('date')['steps'].sum().reset_index()\n        daily_totals.rename(columns={'steps': 'actual_final_total'}, inplace=True)\n        return analyze_weekly_pattern_from_df(daily_totals)\n    except:",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "analyze_weekly_pattern_from_df",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def analyze_weekly_pattern_from_df(valid_days_df):\n    \"\"\"Internal logic using Pandas\"\"\"\n    if valid_days_df.empty: return [0]*7\n    # 0=Mon, 6=Sun\n    valid_days_df['weekday'] = valid_days_df['date'].dt.dayofweek\n    weekday_avgs = valid_days_df.groupby('weekday')['actual_final_total'].mean()\n    # Ensure all 7 days exist (fill missing with 0)\n    weekday_avgs = weekday_avgs.reindex(range(7), fill_value=0)\n    return weekday_avgs.astype(int).tolist()\ndef generate_trend_message(predicted: int, average: float) -> str:",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "generate_trend_message",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def generate_trend_message(predicted: int, average: float) -> str:\n    \"\"\"Standalone helper for basic message generation.\"\"\"\n    if average == 0: return \"Building history...\"\n    ratio = predicted / average\n    if ratio >= 1.25: return \"You're on fire! ðŸ”¥ Way above average.\"\n    if ratio >= 1.1: return \"Great momentum! Beating your average.\"\n    if ratio >= 0.9: return \"Solid consistency. Right on track.\"\n    if ratio >= 0.7: return \"A bit quiet today, keep moving!\"\n    return \"Rest day? Activity is lower than usual.\"\ndef suggest_daily_goal(history, current_weekday_index):",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "suggest_daily_goal",
        "kind": 2,
        "importPath": "analytics",
        "description": "analytics",
        "peekOfCode": "def suggest_daily_goal(history, current_weekday_index):\n    # Filter history for only \"Mondays\" (if today is Monday)\n    relevant_days = [h['steps'] for h in history if h['weekday'] == current_weekday_index]\n    if len(relevant_days) < 3:\n        return 10000 # Default if not enough data\n    # Calculate the 75th percentile (The \"Push\" Goal)\n    smart_goal = np.percentile(relevant_days, 75)\n    # Round to nearest 100\n    return int(round(smart_goal / 100.0) * 100)",
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "ActivityData",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class ActivityData(BaseModel):\n    steps: int\n    weight: float\n    hour: int\n# 2. For Step Prediction (New Feature)\nclass HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "HistoryPoint",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class HistoryPoint(BaseModel):\n    date: str  # Format: \"2023-10-27\"\n    hour: int  # 0-23\n    steps: int\nclass PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "PredictionRequest",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class PredictionRequest(BaseModel):\n    current_steps: int\n    history: List[HistoryPoint]\n# --- API ENDPOINTS ---\n@app.post(\"/calculate_calories\")\nasync def calculate_calories(data: ActivityData):\n    # ---------------------------------------------------------\n    # ðŸ§  PART 1: PREDICT CALORIES\n    # ---------------------------------------------------------\n    if model:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,\n            calories REAL",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_history():\n    conn = sqlite3.connect(DB_FILE)\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    cursor.execute('SELECT * FROM logs ORDER BY id DESC LIMIT 20')\n    rows = cursor.fetchall()\n    conn.close()\n    clean_history = []\n    for row in rows:\n        clean_history.append({",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def home():\n    return {\"status\": \"Online\", \"framework\": \"FastAPI + SQLite\"}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = FastAPI()\n# --- DATABASE SETUP ---\nDB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DB_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DB_FILE = \"step_history.db\"\ndef init_db():\n    \"\"\"Creates the database table if it doesn't exist.\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            time TEXT,\n            steps INTEGER,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "n_samples = 10000\n# 1. Generate Data\nsteps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "steps",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "steps = np.random.randint(100, 25000, n_samples)\nweight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "weight",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "weight = np.random.uniform(50, 120, n_samples)\nhours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "hours",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "hours = np.random.randint(0, 24, n_samples)\ndf = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = pd.DataFrame({'steps': steps, 'weight': weight, 'hour': hours})\n# 2. Intensity Logic\nintensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = []\nfor h in hours:\n    if 6 <= h <= 9: intensity_multiplier.append(1.25)\n    elif 17 <= h <= 20: intensity_multiplier.append(1.15)\n    elif 23 <= h or h <= 5: intensity_multiplier.append(0.85)\n    else: intensity_multiplier.append(1.0)\nintensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "intensity_multiplier",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "intensity_multiplier = np.array(intensity_multiplier)\n# 3. Calculate Target\nbase_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "base_burn",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "base_burn = (steps * 0.045) * (weight / 70) \ncalories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = base_burn * intensity_multiplier\nnoise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "noise",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "noise = np.random.normal(0, 8, n_samples)\ncalories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "calories",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "calories = np.maximum(calories + noise, 0)\n# 4. Train Smaller Model\nprint(\"ðŸ§  Training Optimized Model...\")\n# ðŸŸ¢ CHANGE 1: n_estimators=50 (was 200), max_depth=10 (was 15)\nmodel = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\nmodel.fit(df[['steps', 'weight', 'hour']], calories)\n# 5. Save with Compression\nprint(\"ðŸ’¾ Saving with compression...\")\n# ðŸŸ¢ CHANGE 2: compress=3 drastically reduces file size\njoblib.dump(model, \"calorie_model.pkl\", compress=3)\n# Check File Size\nsize_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "size_mb",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "size_mb = os.path.getsize(\"calorie_model.pkl\") / (1024 * 1024)\nprint(f\"âœ… Success! New model size: {size_mb:.2f} MB\")",
        "detail": "train_model",
        "documentation": {}
    }
]